{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T12:10:23.366561Z",
     "iopub.status.busy": "2022-06-19T12:10:23.365713Z",
     "iopub.status.idle": "2022-06-19T12:10:23.373154Z",
     "shell.execute_reply": "2022-06-19T12:10:23.371867Z",
     "shell.execute_reply.started": "2022-06-19T12:10:23.366517Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "import numpy as np \n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T13:27:40.521265Z",
     "iopub.status.busy": "2022-06-19T13:27:40.520846Z",
     "iopub.status.idle": "2022-06-19T13:27:41.294206Z",
     "shell.execute_reply": "2022-06-19T13:27:41.293369Z",
     "shell.execute_reply.started": "2022-06-19T13:27:40.521226Z"
    }
   },
   "outputs": [],
   "source": [
    "train_root = '../input/homework1/train'\n",
    "val_root = '../input/homework1/val'\n",
    "\n",
    "# grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "# rotation = transforms.RandomRotation(degrees=(-8, 8), expand=True)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "rs = transforms.Resize((224, 224))\n",
    "\n",
    "train_transform = transforms.Compose([rs,\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=(-8, 8), expand=False),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "val_transform = transforms.Compose([rs, \n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(train_root, transform=train_transform)\n",
    "valset = torchvision.datasets.ImageFolder(val_root, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T12:10:29.229878Z",
     "iopub.status.busy": "2022-06-19T12:10:29.229478Z",
     "iopub.status.idle": "2022-06-19T12:10:29.248895Z",
     "shell.execute_reply": "2022-06-19T12:10:29.247991Z",
     "shell.execute_reply.started": "2022-06-19T12:10:29.229838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(trainset[0], tuple)\n",
    "assert len(trainset[0]) == 2\n",
    "assert isinstance(trainset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T12:10:30.911303Z",
     "iopub.status.busy": "2022-06-19T12:10:30.910392Z",
     "iopub.status.idle": "2022-06-19T12:10:30.917383Z",
     "shell.execute_reply": "2022-06-19T12:10:30.916367Z",
     "shell.execute_reply.started": "2022-06-19T12:10:30.911268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T13:43:20.583124Z",
     "iopub.status.busy": "2022-06-19T13:43:20.582232Z",
     "iopub.status.idle": "2022-06-19T13:43:20.589781Z",
     "shell.execute_reply": "2022-06-19T13:43:20.588532Z",
     "shell.execute_reply.started": "2022-06-19T13:43:20.583076Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch size \n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "val_dataloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T13:43:21.761190Z",
     "iopub.status.busy": "2022-06-19T13:43:21.760764Z",
     "iopub.status.idle": "2022-06-19T13:43:22.427199Z",
     "shell.execute_reply": "2022-06-19T13:43:22.426374Z",
     "shell.execute_reply.started": "2022-06-19T13:43:21.761155Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "n_epochs = 20\n",
    "model = models.resnet50(pretrained=True)  # TODO resnet18\n",
    "model.fc = nn.Linear(model.fc.in_features, 200)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # TODO was 0.02\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0, last_epoch=- 1, verbose=True)\n",
    "# model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.25, training=m.training))  # TODO\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T13:43:24.070787Z",
     "iopub.status.busy": "2022-06-19T13:43:24.070287Z",
     "iopub.status.idle": "2022-06-19T13:43:24.093954Z",
     "shell.execute_reply": "2022-06-19T13:43:24.093096Z",
     "shell.execute_reply.started": "2022-06-19T13:43:24.070749Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
    "    train_epoch_loss, train_epoch_true_hits = torch.empty(0).to(device), torch.empty(0)\n",
    "    train_predicted_labels, train_real_labels, train_losses = [], [], []\n",
    "    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n",
    "    model.train()\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        y_pred = model(imgs)\n",
    "        train_epoch_loss = train_epoch_loss#.to(device)\n",
    "        train_epoch_true_hits = train_epoch_true_hits#.to(device)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_epoch_loss = torch.cat((train_epoch_loss, loss.unsqueeze(0) / labels.size(0)))\n",
    "        train_loss_log.append(loss.data / labels.size(0))\n",
    "        # log accuracy for the current epoch and the whole training history\n",
    "        pred_classes = torch.argmax(y_pred, dim=-1)\n",
    "        train_predicted_labels += pred_classes.tolist()\n",
    "        train_real_labels += labels.tolist()\n",
    "        \n",
    "    return train_loss_log, train_predicted_labels, train_real_labels                  \n",
    "\n",
    "def predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n",
    "    all_predicted_labels, all_real_labels, all_losses =  [], [], []\n",
    "    val_accuracy = []\n",
    "    model.eval()   \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_dataloader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            for i in range(len(y_pred)):\n",
    "                all_losses.append(criterion(y_pred[i], labels[i]).tolist())\n",
    "            pred_classes = torch.argmax(y_pred, dim=-1)\n",
    "            all_predicted_labels += pred_classes.tolist()\n",
    "            all_real_labels += labels.tolist()\n",
    "    return all_losses, all_predicted_labels, all_real_labels                  \n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
    "    model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        t_los, t_acc, t_lab = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "        train_accuracy = accuracy_score(t_acc, t_lab)\n",
    "        v_los, v_acc, v_lab = predict(model, val_dataloader, criterion, device)\n",
    "        val_accuracy = accuracy_score(v_acc, v_lab)\n",
    "        print(f'{epoch}/{n_epochs}')\n",
    "        #scheduler.step()  # TODO\n",
    "        print(\"Train acc:\", train_accuracy)\n",
    "        print(\"Val acc:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T13:43:26.160857Z",
     "iopub.status.busy": "2022-06-19T13:43:26.160123Z",
     "iopub.status.idle": "2022-06-19T16:46:05.731784Z",
     "shell.execute_reply": "2022-06-19T16:46:05.730154Z",
     "shell.execute_reply.started": "2022-06-19T13:43:26.160817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20\n",
      "Train acc: 0.54017\n",
      "Val acc: 0.5891\n",
      "1/20\n",
      "Train acc: 0.65462\n",
      "Val acc: 0.6174\n",
      "2/20\n",
      "Train acc: 0.70799\n",
      "Val acc: 0.6562\n",
      "3/20\n",
      "Train acc: 0.74655\n",
      "Val acc: 0.6685\n",
      "4/20\n",
      "Train acc: 0.78532\n",
      "Val acc: 0.6666\n",
      "5/20\n",
      "Train acc: 0.81394\n",
      "Val acc: 0.6774\n",
      "6/20\n",
      "Train acc: 0.83868\n",
      "Val acc: 0.6859\n",
      "7/20\n",
      "Train acc: 0.8639\n",
      "Val acc: 0.6943\n",
      "8/20\n",
      "Train acc: 0.88098\n",
      "Val acc: 0.6868\n",
      "9/20\n",
      "Train acc: 0.90012\n",
      "Val acc: 0.6848\n",
      "10/20\n",
      "Train acc: 0.91357\n",
      "Val acc: 0.6896\n",
      "11/20\n",
      "Train acc: 0.92751\n",
      "Val acc: 0.6935\n",
      "12/20\n",
      "Train acc: 0.9369\n",
      "Val acc: 0.6972\n",
      "13/20\n",
      "Train acc: 0.94877\n",
      "Val acc: 0.6943\n",
      "14/20\n",
      "Train acc: 0.95642\n",
      "Val acc: 0.6995\n",
      "15/20\n",
      "Train acc: 0.96168\n",
      "Val acc: 0.703\n",
      "16/20\n",
      "Train acc: 0.96799\n",
      "Val acc: 0.7091\n",
      "17/20\n",
      "Train acc: 0.9715\n",
      "Val acc: 0.7068\n",
      "18/20\n",
      "Train acc: 0.97327\n",
      "Val acc: 0.7104\n",
      "19/20\n",
      "Train acc: 0.97808\n",
      "Val acc: 0.7067\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler=None)  # TODO scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T16:52:25.314449Z",
     "iopub.status.busy": "2022-06-19T16:52:25.313709Z",
     "iopub.status.idle": "2022-06-19T16:52:56.280286Z",
     "shell.execute_reply": "2022-06-19T16:52:56.279132Z",
     "shell.execute_reply.started": "2022-06-19T16:52:25.314384Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, pred_labels, real_labels = predict(model, val_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T16:53:09.933191Z",
     "iopub.status.busy": "2022-06-19T16:53:09.932778Z",
     "iopub.status.idle": "2022-06-19T16:53:09.941406Z",
     "shell.execute_reply": "2022-06-19T16:53:09.940369Z",
     "shell.execute_reply.started": "2022-06-19T16:53:09.933151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_labels) == len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T16:53:11.393591Z",
     "iopub.status.busy": "2022-06-19T16:53:11.392823Z",
     "iopub.status.idle": "2022-06-19T16:53:11.411382Z",
     "shell.execute_reply": "2022-06-19T16:53:11.410624Z",
     "shell.execute_reply.started": "2022-06-19T16:53:11.393550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7067"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(real_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T16:53:43.260965Z",
     "iopub.status.busy": "2022-06-19T16:53:43.260569Z",
     "iopub.status.idle": "2022-06-19T16:54:13.538484Z",
     "shell.execute_reply": "2022-06-19T16:54:13.536827Z",
     "shell.execute_reply.started": "2022-06-19T16:53:43.260932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка за это задание составит 6.079411764705882 баллов\n"
     ]
    }
   ],
   "source": [
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(valset)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Оценка за это задание составит {} баллов\".format(min(10, 10 * (accuracy - 0.5) / 0.34)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T16:55:22.041089Z",
     "iopub.status.busy": "2022-06-19T16:55:22.040486Z",
     "iopub.status.idle": "2022-06-19T17:22:59.654023Z",
     "shell.execute_reply": "2022-06-19T17:22:59.652515Z",
     "shell.execute_reply.started": "2022-06-19T16:55:22.041048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20\n",
      "Train acc: 0.98008\n",
      "Val acc: 0.7131\n",
      "1/20\n",
      "Train acc: 0.98317\n",
      "Val acc: 0.7157\n",
      "2/20\n",
      "Train acc: 0.98441\n",
      "Val acc: 0.7153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/1745978284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Что если сделать еще пару трейн эпох?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33/1193254699.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mt_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mv_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_33/1193254699.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    150\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                   \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                   maximize=maximize,)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmaximize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Что если сделать еще пару трейн эпох?\n",
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler=None)  # TODO scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T17:23:28.797414Z",
     "iopub.status.busy": "2022-06-19T17:23:28.796692Z",
     "iopub.status.idle": "2022-06-19T17:24:01.317732Z",
     "shell.execute_reply": "2022-06-19T17:24:01.316598Z",
     "shell.execute_reply.started": "2022-06-19T17:23:28.797371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка за это задание составит 6.335294117647059 баллов\n"
     ]
    }
   ],
   "source": [
    "# После небольшого дообучения модели. Дообучения прервала самостоятельно, так как обучение занимает много времени\n",
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(valset)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Оценка за это задание составит {} баллов\".format(min(10, 10 * (accuracy - 0.5) / 0.34)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоговый результат выше - Оценка за это задание составит 6.335294117647059 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (про улучшения https://datahacker.rs/016-pytorch-three-hacks-for-improving-the-performance-of-deep-neural-networks-transfer-learning-data-augmentation-and-scheduling-the-learning-rate-in-pytorch/)\n",
    "Первые попытки дообучить модель из первого задания:\n",
    "1) Возьмем предобученную модель **resnet18**, lr = 0.01, batch = 50, norm, rotate, flip из предыдущего задания (но включили нормировку). Получилось максимальное качество 50.3%\n",
    "\n",
    "2) **Resnet18** без нормализации. Получаем 50% на 9 эпохе при train_accuracy = 0.7. Запустим 20 эпох при lr=0.015, лучший результат 51.2 на 14 эпохе, время обучения очень долгое последней эпохи\n",
    "\n",
    "2.0) **Resnet18** без нормализации. Обучила 50 эпох, после 24 качество начало заметно ухудшаться. Максимум - 51%, он достигается уже на 15 эпохе. Был добавлен dropout для теста model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training)). После 20й эпохи качество начало резко ухудшаться и упало до 44%, потом не увеличивалось. Возможно 0.5 - это слишком много\n",
    "\n",
    "2.1) Модель **resnet 50** - максимальное качество 54% на 5 эпохе, все по-старому, оставила dropout, хоть train_acc = 74, модель топчется на одном месте, lr = 0.02 велик, а dropout 0.5 - это слишком много\n",
    "\n",
    "2.2) Модель **resnext50 - 32-4d** просто проверить. Dropout = 0.25, lr = 0.02, batch = 100 - очень долго, остановила\n",
    "\n",
    "3) Вернусь к обычной **resnet-50**, batch = 100, dropout off, lr = 0.02 - accuracy 0.554 на 6 эпохе\n",
    "\n",
    "3.1) **resnet-50**. Изменила rotation на -8, +8 + expand=False, 50% качества на 2й эпохе,  56.14% на 7й эпохе\n",
    "\n",
    "3.2) **resnet-50**. Изменила rotation на -8, +8 + expand=True, 48% качества на 2й эпохе, 56.3 % на 7й эпохе, 57 на 10й acc_train = 92. Если и expand=True дает эффект, то не очень очевидный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 продолжение:\n",
    "**Воспользуемся отменой на ограничение ресайза картинок. \n",
    "Из документации предобученных моделей: https://pytorch.org/vision/stable/models.html и кода: https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101\n",
    "имплементируем нормализацию transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) и нужный размер для ресайза. Сделаем ресайз сразу до нужного размера (224х224), обучим resnet-50.\n",
    "**\n",
    "\n",
    "1) Добавлен ресайз картинок как в описании pytorch для предобученной модели resnet50 до размеров, принимаемых на вход по умолчанию - 224х224. Получили качество 67% при ресайзе картинок на первых 2х эпохах без ротации картинки и без шедулера. \n",
    "\n",
    "2) Без шедулера, но с ротацией картинок на 2й эпохе 59%, на 7й эпохе 65. Lr = 0.02 - очень большой, обучение очень медленное, качество быстро перестает расти и топчется несколько эпох на одном месте\n",
    "\n",
    "3) Поставим lr = 0.01, С таким lr качество на 2й эпохе 65. Кажется, что так эффективнее. Шедулер отключен. Обучим 20+ эпох в поисках высокого качества. На 20ти эпохах максимум 71% качества. \n",
    "Попробуем чуть-чуть дообучить модель при тех же параметрах \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
