{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport tqdm\nfrom torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score\nimport warnings\n\nimport numpy as np \nfrom IPython.display import clear_output\nfrom tqdm.auto import tqdm, trange","metadata":{"execution":{"iopub.status.busy":"2022-06-19T12:10:23.365713Z","iopub.execute_input":"2022-06-19T12:10:23.366561Z","iopub.status.idle":"2022-06-19T12:10:23.373154Z","shell.execute_reply.started":"2022-06-19T12:10:23.366517Z","shell.execute_reply":"2022-06-19T12:10:23.371867Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_root = '../input/homework1/train'\nval_root = '../input/homework1/val'\n\n# grayscale = transforms.Grayscale(num_output_channels=1)\n# rotation = transforms.RandomRotation(degrees=(-8, 8), expand=True)\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\nrs = transforms.Resize((224, 224))\n\ntrain_transform = transforms.Compose([rs,\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(degrees=(-8, 8), expand=False),\n        transforms.ToTensor(),\n        normalize,\n    ])\nval_transform = transforms.Compose([rs, \n        transforms.ToTensor(),\n        normalize,\n])\n\ntrainset = torchvision.datasets.ImageFolder(train_root, transform=train_transform)\nvalset = torchvision.datasets.ImageFolder(val_root, transform=val_transform)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:27:40.520846Z","iopub.execute_input":"2022-06-19T13:27:40.521265Z","iopub.status.idle":"2022-06-19T13:27:41.294206Z","shell.execute_reply.started":"2022-06-19T13:27:40.521226Z","shell.execute_reply":"2022-06-19T13:27:41.293369Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Just very simple sanity checks\nassert isinstance(trainset[0], tuple)\nassert len(trainset[0]) == 2\nassert isinstance(trainset[1][1], int)\nprint(\"tests passed\")","metadata":{"execution":{"iopub.status.busy":"2022-06-19T12:10:29.229478Z","iopub.execute_input":"2022-06-19T12:10:29.229878Z","iopub.status.idle":"2022-06-19T12:10:29.248895Z","shell.execute_reply.started":"2022-06-19T12:10:29.229838Z","shell.execute_reply":"2022-06-19T12:10:29.247991Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"tests passed\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():    \n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-19T12:10:30.910392Z","iopub.execute_input":"2022-06-19T12:10:30.911303Z","iopub.status.idle":"2022-06-19T12:10:30.917383Z","shell.execute_reply.started":"2022-06-19T12:10:30.911268Z","shell.execute_reply":"2022-06-19T12:10:30.916367Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"# batch size \nbatch_size = 64\nnum_workers = 2\ntrain_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\nval_dataloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:43:20.582232Z","iopub.execute_input":"2022-06-19T13:43:20.583124Z","iopub.status.idle":"2022-06-19T13:43:20.589781Z","shell.execute_reply.started":"2022-06-19T13:43:20.583076Z","shell.execute_reply":"2022-06-19T13:43:20.588532Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\n\nn_epochs = 20\nmodel = models.resnet50(pretrained=True)  # TODO resnet18\nmodel.fc = nn.Linear(model.fc.in_features, 200)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # TODO was 0.02\ncriterion = nn.CrossEntropyLoss()\n\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0, last_epoch=- 1, verbose=True)\n# model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.25, training=m.training))  # TODO\n\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:43:21.760764Z","iopub.execute_input":"2022-06-19T13:43:21.761190Z","iopub.status.idle":"2022-06-19T13:43:22.427199Z","shell.execute_reply.started":"2022-06-19T13:43:21.761155Z","shell.execute_reply":"2022-06-19T13:43:22.426374Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n    train_epoch_loss, train_epoch_true_hits = torch.empty(0).to(device), torch.empty(0)\n    train_predicted_labels, train_real_labels, train_losses = [], [], []\n    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n    model.train()\n    \n    for i, (imgs, labels) in enumerate(train_dataloader):\n        imgs, labels = imgs.to(device), labels.to(device)\n        y_pred = model(imgs)\n        train_epoch_loss = train_epoch_loss#.to(device)\n        train_epoch_true_hits = train_epoch_true_hits#.to(device)\n        loss = criterion(y_pred, labels)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        train_epoch_loss = torch.cat((train_epoch_loss, loss.unsqueeze(0) / labels.size(0)))\n        train_loss_log.append(loss.data / labels.size(0))\n        # log accuracy for the current epoch and the whole training history\n        pred_classes = torch.argmax(y_pred, dim=-1)\n        train_predicted_labels += pred_classes.tolist()\n        train_real_labels += labels.tolist()\n        \n    return train_loss_log, train_predicted_labels, train_real_labels                  \n\ndef predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n    all_predicted_labels, all_real_labels, all_losses =  [], [], []\n    val_accuracy = []\n    model.eval()   \n    with torch.no_grad():\n        for imgs, labels in val_dataloader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            y_pred = model(imgs)\n\n            for i in range(len(y_pred)):\n                all_losses.append(criterion(y_pred[i], labels[i]).tolist())\n            pred_classes = torch.argmax(y_pred, dim=-1)\n            all_predicted_labels += pred_classes.tolist()\n            all_real_labels += labels.tolist()\n    return all_losses, all_predicted_labels, all_real_labels                  \n\ndef train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n    model.to(device)\n    for epoch in range(n_epochs):\n        t_los, t_acc, t_lab = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n        train_accuracy = accuracy_score(t_acc, t_lab)\n        v_los, v_acc, v_lab = predict(model, val_dataloader, criterion, device)\n        val_accuracy = accuracy_score(v_acc, v_lab)\n        print(f'{epoch}/{n_epochs}')\n        #scheduler.step()  # TODO\n        print(\"Train acc:\", train_accuracy)\n        print(\"Val acc:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:43:24.070287Z","iopub.execute_input":"2022-06-19T13:43:24.070787Z","iopub.status.idle":"2022-06-19T13:43:24.093954Z","shell.execute_reply.started":"2022-06-19T13:43:24.070749Z","shell.execute_reply":"2022-06-19T13:43:24.093096Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler=None)  # TODO scheduler","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:43:26.160123Z","iopub.execute_input":"2022-06-19T13:43:26.160857Z","iopub.status.idle":"2022-06-19T16:46:05.731784Z","shell.execute_reply.started":"2022-06-19T13:43:26.160817Z","shell.execute_reply":"2022-06-19T16:46:05.730154Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"0/20\nTrain acc: 0.54017\nVal acc: 0.5891\n1/20\nTrain acc: 0.65462\nVal acc: 0.6174\n2/20\nTrain acc: 0.70799\nVal acc: 0.6562\n3/20\nTrain acc: 0.74655\nVal acc: 0.6685\n4/20\nTrain acc: 0.78532\nVal acc: 0.6666\n5/20\nTrain acc: 0.81394\nVal acc: 0.6774\n6/20\nTrain acc: 0.83868\nVal acc: 0.6859\n7/20\nTrain acc: 0.8639\nVal acc: 0.6943\n8/20\nTrain acc: 0.88098\nVal acc: 0.6868\n9/20\nTrain acc: 0.90012\nVal acc: 0.6848\n10/20\nTrain acc: 0.91357\nVal acc: 0.6896\n11/20\nTrain acc: 0.92751\nVal acc: 0.6935\n12/20\nTrain acc: 0.9369\nVal acc: 0.6972\n13/20\nTrain acc: 0.94877\nVal acc: 0.6943\n14/20\nTrain acc: 0.95642\nVal acc: 0.6995\n15/20\nTrain acc: 0.96168\nVal acc: 0.703\n16/20\nTrain acc: 0.96799\nVal acc: 0.7091\n17/20\nTrain acc: 0.9715\nVal acc: 0.7068\n18/20\nTrain acc: 0.97327\nVal acc: 0.7104\n19/20\nTrain acc: 0.97808\nVal acc: 0.7067\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, pred_labels, real_labels = predict(model, val_dataloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T16:52:25.313709Z","iopub.execute_input":"2022-06-19T16:52:25.314449Z","iopub.status.idle":"2022-06-19T16:52:56.280286Z","shell.execute_reply.started":"2022-06-19T16:52:25.314384Z","shell.execute_reply":"2022-06-19T16:52:56.279132Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"len(pred_labels) == len(valset)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T16:53:09.932778Z","iopub.execute_input":"2022-06-19T16:53:09.933191Z","iopub.status.idle":"2022-06-19T16:53:09.941406Z","shell.execute_reply.started":"2022-06-19T16:53:09.933151Z","shell.execute_reply":"2022-06-19T16:53:09.940369Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"accuracy_score(real_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T16:53:11.392823Z","iopub.execute_input":"2022-06-19T16:53:11.393591Z","iopub.status.idle":"2022-06-19T16:53:11.411382Z","shell.execute_reply.started":"2022-06-19T16:53:11.393550Z","shell.execute_reply":"2022-06-19T16:53:11.410624Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"0.7067"},"metadata":{}}]},{"cell_type":"code","source":"all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\nassert len(predicted_labels) == len(valset)\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"Оценка за это задание составит {} баллов\".format(min(10, 10 * (accuracy - 0.5) / 0.34)))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T16:53:43.260569Z","iopub.execute_input":"2022-06-19T16:53:43.260965Z","iopub.status.idle":"2022-06-19T16:54:13.538484Z","shell.execute_reply.started":"2022-06-19T16:53:43.260932Z","shell.execute_reply":"2022-06-19T16:54:13.536827Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Оценка за это задание составит 6.079411764705882 баллов\n","output_type":"stream"}]},{"cell_type":"code","source":"# Что если сделать еще пару трейн эпох?\ntrain(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler=None)  # TODO scheduler","metadata":{"execution":{"iopub.status.busy":"2022-06-19T16:55:22.040486Z","iopub.execute_input":"2022-06-19T16:55:22.041089Z","iopub.status.idle":"2022-06-19T17:22:59.654023Z","shell.execute_reply.started":"2022-06-19T16:55:22.041048Z","shell.execute_reply":"2022-06-19T17:22:59.652515Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"0/20\nTrain acc: 0.98008\nVal acc: 0.7131\n1/20\nTrain acc: 0.98317\nVal acc: 0.7157\n2/20\nTrain acc: 0.98441\nVal acc: 0.7153\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1745978284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Что если сделать еще пару трейн эпох?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/1193254699.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mt_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mv_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1193254699.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    150\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                   \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                   maximize=maximize,)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmaximize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# После небольшого дообучения модели. Дообучения прервала самостоятельно, так как обучение занимает много времени\nall_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\nassert len(predicted_labels) == len(valset)\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"Оценка за это задание составит {} баллов\".format(min(10, 10 * (accuracy - 0.5) / 0.34)))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T17:23:28.796692Z","iopub.execute_input":"2022-06-19T17:23:28.797414Z","iopub.status.idle":"2022-06-19T17:24:01.317732Z","shell.execute_reply.started":"2022-06-19T17:23:28.797371Z","shell.execute_reply":"2022-06-19T17:24:01.316598Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Оценка за это задание составит 6.335294117647059 баллов\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Итоговый результат выше - Оценка за это задание составит 6.335294117647059 баллов","metadata":{}},{"cell_type":"markdown","source":"## Задание 2 (про улучшения https://datahacker.rs/016-pytorch-three-hacks-for-improving-the-performance-of-deep-neural-networks-transfer-learning-data-augmentation-and-scheduling-the-learning-rate-in-pytorch/)\nПервые попытки дообучить модель из первого задания:\n1) Возьмем предобученную модель **resnet18**, lr = 0.01, batch = 50, norm, rotate, flip из предыдущего задания (но включили нормировку). Получилось максимальное качество 50.3%\n\n2) **Resnet18** без нормализации. Получаем 50% на 9 эпохе при train_accuracy = 0.7. Запустим 20 эпох при lr=0.015, лучший результат 51.2 на 14 эпохе, время обучения очень долгое последней эпохи\n\n2.0) **Resnet18** без нормализации. Обучила 50 эпох, после 24 качество начало заметно ухудшаться. Максимум - 51%, он достигается уже на 15 эпохе. Был добавлен dropout для теста model.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training)). После 20й эпохи качество начало резко ухудшаться и упало до 44%, потом не увеличивалось. Возможно 0.5 - это слишком много\n\n2.1) Модель **resnet 50** - максимальное качество 54% на 5 эпохе, все по-старому, оставила dropout, хоть train_acc = 74, модель топчется на одном месте, lr = 0.02 велик, а dropout 0.5 - это слишком много\n\n2.2) Модель **resnext50 - 32-4d** просто проверить. Dropout = 0.25, lr = 0.02, batch = 100 - очень долго, остановила\n\n3) Вернусь к обычной **resnet-50**, batch = 100, dropout off, lr = 0.02 - accuracy 0.554 на 6 эпохе\n\n3.1) **resnet-50**. Изменила rotation на -8, +8 + expand=False, 50% качества на 2й эпохе,  56.14% на 7й эпохе\n\n3.2) **resnet-50**. Изменила rotation на -8, +8 + expand=True, 48% качества на 2й эпохе, 56.3 % на 7й эпохе, 57 на 10й acc_train = 92. Если и expand=True дает эффект, то не очень очевидный","metadata":{}},{"cell_type":"markdown","source":"## Задание 2 продолжение:\n**Воспользуемся отменой на ограничение ресайза картинок. \nИз документации предобученных моделей: https://pytorch.org/vision/stable/models.html и кода: https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101\nимплементируем нормализацию transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) и нужный размер для ресайза. Сделаем ресайз сразу до нужного размера (224х224), обучим resnet-50.\n**\n\n1) Добавлен ресайз картинок как в описании pytorch для предобученной модели resnet50 до размеров, принимаемых на вход по умолчанию - 224х224. Получили качество 67% при ресайзе картинок на первых 2х эпохах без ротации картинки и без шедулера. \n\n2) Без шедулера, но с ротацией картинок на 2й эпохе 59%, на 7й эпохе 65. Lr = 0.02 - очень большой, обучение очень медленное, качество быстро перестает расти и топчется несколько эпох на одном месте\n\n3) Поставим lr = 0.01, С таким lr качество на 2й эпохе 65. Кажется, что так эффективнее. Шедулер отключен. Обучим 20+ эпох в поисках высокого качества. На 20ти эпохах максимум 71% качества. \nПопробуем чуть-чуть дообучить модель при тех же параметрах \n\n","metadata":{}}]}